{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xXwWCW5r9aAA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introducción"
      ],
      "metadata": {
        "id": "4IsmUnJXJYS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook se presentarán algunas herramientas útiles para cualquier persona que trabaje en programación. El objetivo de esta clase es que se familiaricen con estas herramientas y puedan decidir cuáles son las más adecuadas para cada uno de sus proyectos y futuro trabajo.\n",
        "\n",
        "Es importante destacar que muchas de estas herramientas están diseñadas para usarse en un entorno local, es decir, en el computador que ustedes están utilizando. Por esta razón, será necesario aprender a instalar y gestionar todas las dependencias y librerías, que hasta ahora hemos dado por sentado que están disponibles en Google Colab. En muchos casos, esta instalación puede resultar compleja, especialmente para aquellas librerías que requieren uso de GPU.\n",
        "\n",
        "Trabajar en un entorno local presenta tanto ventajas como desventajas. Entre las principales ventajas se encuentra la facilidad para acceder a datos almacenados localmente, como imágenes, audios o cualquier otro tipo de archivo, los cuales suelen ser difíciles de manejar en plataformas en línea. Por otro lado, la mayor desventaja radica en las limitaciones de cómputo propias del equipo local, lo cual puede restringir el rendimiento y la capacidad de procesamiento."
      ],
      "metadata": {
        "id": "HUPnTxfa_Dt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python"
      ],
      "metadata": {
        "id": "tgJf_rnIFX-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalar python: https://www.python.org/downloads/release/python-3109/\n",
        "\n",
        "[[https://www.python.org/downloads/]]"
      ],
      "metadata": {
        "id": "hydNKRC7Fe3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Editores de código"
      ],
      "metadata": {
        "id": "kafDo2wmBu8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducción: Editores de código"
      ],
      "metadata": {
        "id": "mpcdyxtMxAoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como ya hemos visto en clases, todo el código que escribimos es, en esencia, texto. El lenguaje de programación interpreta estas líneas según una sintaxis específica para cada caso, ejecutando las instrucciones correspondientes.\n",
        "\n",
        "Para que el computador pueda interpretar y ejecutar este código, es necesario que tenga instalado internamente el lenguaje de programación correspondiente. Este, a su vez, no requiere más que la consola para funcionar.\n",
        "\n",
        "La consola varía según el sistema operativo. En Windows, se llama \"cmd\" (Símbolo del sistema), mientras que en Mac se denomina \"Terminal\". En ambos casos, acceder a ella es sencillo: basta con buscar \"cmd\" o \"Terminal\" en la barra de búsqueda o Spotlight, lo que abrirá una ventana de consola similar a esta:\n",
        "\n",
        "Ejemplo windows:\n",
        "\n",
        "![texto del vínculo](https://upload.wikimedia.org/wikipedia/commons/b/b3/Command_Prompt_on_Windows_10_RTM.png)\n",
        "\n",
        "Ejemplo Mac:\n",
        "\n",
        "<img src=\"https://help.apple.com/assets/65DFB7A79DFEC61A7A0517AC/65DFB7A793CD15C0410BA37D/es_419/ff5c51a873b9efb253e9f0d0d6f19d53.png\" alt=\"texto del vínculo\" width=\"700\"/>"
      ],
      "metadata": {
        "id": "oUM8s8GUBzIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con la consola abierta, si Python ya está instalado, basta con escribir \"python\" para que el equipo comience a interpretar comandos en ese lenguaje. Esto mostrará una interfaz similar a la siguiente:\n",
        "\n",
        "Correr Python en la consola:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaxWesterhout/Sistemas-de-Diagnostico-y-Tratamiento-I/refs/heads/main/data/Clase10/ConsolaPython.png\" alt=\"texto del vínculo\" width=\"700\"/>\n",
        "\n",
        "Además, si tienes un script (archivo de Python), puedes ejecutarlo directamente desde la consola escribiendo python NombreArchivo.py. Por ejemplo, si el script se llama HolaMundo.py y contiene únicamente la línea de código print(\"Hola Mundo\"), su ejecución en la consola sería como se muestra en la siguiente imagen:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaxWesterhout/Sistemas-de-Diagnostico-y-Tratamiento-I/refs/heads/main/data/Clase10/ConsolaPython2.png\" alt=\"texto del vínculo\" width=\"700\"/>\n",
        "\n",
        "Si lo analizamos, esta interfaz resulta poco práctica y, en general, incómoda, pues uno espera contar con la misma facilidad que ofrece un notebook. Por eso, en la práctica, para evitar trabajar directamente en la consola, se utilizan los editores de código. Estas aplicaciones permiten visualizar el código de forma más intuitiva, resaltando con colores diferentes secciones y mostrando claramente la sintaxis del lenguaje. Todo esto tiene como objetivo alejarnos lo máximo posible de la consola y facilitar la programación.\n"
      ],
      "metadata": {
        "id": "ekarMX3rhHCr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comandos utilies de la consola:\n",
        "\n",
        "\n",
        "\n",
        "*   cd\n",
        "*   cd ..\n",
        "*   cls\n",
        "*   exit\n",
        "\n"
      ],
      "metadata": {
        "id": "gNjuMNjX0NQP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visual Studio Code"
      ],
      "metadata": {
        "id": "bNp32kphxD8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9a/Visual_Studio_Code_1.35_icon.svg/1200px-Visual_Studio_Code_1.35_icon.svg.png\" width=\"100\"/>\n",
        "\n",
        "Link descarga: https://code.visualstudio.com/download\n",
        "\n",
        "Visual Studio Code es un editor de código que generalmente se destaca como uno de los mejores. A diferencia de otros editores, Visual Studio Code está conectado a un servidor de extensiones que permite mejorar y personalizar la interfaz según las necesidades del usuario, de forma progresiva.\n",
        "\n",
        "Sin embargo, antes de explorar estas funcionalidades avanzadas, es importante entender lo básico de este editor.\n",
        "\n",
        "A continuación, se muestra la pestaña de inicio al abrir Visual Studio Code:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaxWesterhout/Sistemas-de-Diagnostico-y-Tratamiento-I/refs/heads/main/data/Clase10/VisualStudioBordes.png\" width=\"700\"/>\n",
        "\n",
        "La imagen muestra enmarcadas las barras de opciones y algunos íconos, cuya función general es la siguiente:\n",
        "\n",
        "* Barra superior: Permite editar las vistas, abrir terminales, cambiar de carpeta, entre otras opciones.\n",
        "\n",
        "* Barra lateral izquierda: Muestra los archivos de la carpeta abierta y las extensiones instaladas en Visual Studio Code.\n",
        "\n",
        "* Ícono de engranaje: Desde aquí se puede cambiar el perfil del usuario y modificar el tema del editor.\n",
        "\n",
        "* Ícono de lupa: Permite hacer zoom en la interfaz.\n"
      ],
      "metadata": {
        "id": "Bn-Uf-qDxRM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extensiones"
      ],
      "metadata": {
        "id": "vvCxpfq5IAE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tal como se mencionó anteriormente, Visual Studio Code ofrece una serie de extensiones que permiten personalizar y mejorar la interfaz y experiencia del usuario. Para esta clase, recomiendo instalar las siguientes extensiones:\n",
        "\n",
        "* Python [Pylance + Python Debugger]: Proporciona soporte avanzado para Python, incluyendo autocompletado inteligente, análisis de código, y herramientas para depuración.\n",
        "\n",
        "* Jupyter Notebook: Permite abrir, editar y ejecutar archivos Jupyter Notebook (.ipynb) directamente desde Visual Studio Code, facilitando el trabajo con notebooks de manera local.\n",
        "\n",
        "* vscode-icons: Mejora la visualización de archivos y carpetas añadiendo íconos personalizados según el tipo de archivo, haciendo la navegación más intuitiva.\n",
        "\n",
        "* Project Manager: Facilita la organización y el acceso rápido a diferentes proyectos desde una misma interfaz, permitiendo cambiar entre ellos de manera sencilla.\n",
        "\n",
        "Con todas estas extensiones, editar código resulta mucho más intuitivo y cómodo, disminuyendo las diferencias entre trabajar en Google Colab y hacerlo localmente.\n",
        "\n",
        "Lo último que debemos considerar son las librerías que Google Colab tiene preinstaladas. Como Colab incluye muchas dependencias listas para usar al crear un notebook, primero debemos instalar manualmente estas librerías en nuestro entorno local para poder ejecutar código similar sin inconvenientes.\n"
      ],
      "metadata": {
        "id": "m3dOyfpZKpeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entorno Virtual"
      ],
      "metadata": {
        "id": "3BC9t_fxEP1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de instalar las librerías faltantes, es importante crear un entorno virtual. Un entorno virtual es una buena práctica para gestionar instalaciones de librerías, ya que crea una especie de “mini-perfil” que mantiene las dependencias dentro de una carpeta específica sin afectar al resto del sistema. Esto es especialmente relevante cuando trabajamos en múltiples proyectos que pueden requerir diferentes versiones de una misma librería, algo que sería imposible manejar sin entornos virtuales.\n",
        "\n",
        "Además, esta práctica es fundamental para proyectos grandes, donde la reproducibilidad es clave: se espera poder ejecutar el mismo código en distintos equipos sin problemas. Por ello, se han desarrollado métodos para “congelar” y “clonar” entornos virtuales, asegurando que las mismas dependencias estén disponibles en diferentes máquinas. Este proceso de congelamiento y clonación lo abordaremos en las actividades prácticas.\n",
        "\n",
        "Para crear un entorno virtual en Visual Studio Code, se deben seguir estos pasos:\n",
        "\n",
        "1. Seleccionar la carpeta donde trabajaremos (esto es extremadamente importante).\n",
        "\n",
        "2. Presionar Ctrl + Shift + P y escribir > Python: Create Environment...\n",
        "\n",
        "3. Elegir la versión de Python que se desea usar (en caso de tener más de una instalada).\n",
        "\n",
        "Esto creará automáticamente el entorno virtual, generando una carpeta llamada por defecto \".venv\". Además, en la esquina inferior derecha aparecerá indicado que la versión de Python activa corresponde a este entorno, por ejemplo: Python 3.12.10 (\".venv\").\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaxWesterhout/Sistemas-de-Diagnostico-y-Tratamiento-I/refs/heads/main/data/Clase10/VisualStudio2.png\" width=\"700\"/>\n"
      ],
      "metadata": {
        "id": "iD6EciW4Da-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instalar librerías"
      ],
      "metadata": {
        "id": "GcoLTTfxTSaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esto ya podemos instalar las librerías que necesitaremos, para ello el método más común corresponde al uso de la función \"pip\", la cual viene instalada internamente en Python. Para instalar una librería basta simplemente con colocar \"pip install NombreLibreria\", en donde uno puede hacer esta operación directamente en la terminal de visual o desde un archivo/notebook colocando la misma línea pero incluyendo un \"!\" al inicio de esta (\"!pip install NombreLibreria\").\n",
        "\n",
        "Ejemplos:\n",
        "\n",
        "*   pip install numpy (terminal) / !pip install numpy (notebook)\n",
        "*   pip install scikit-learn (terminal)/ !pip install scikit-learn (notebook)\n",
        "\n",
        "En ciertos casos, algunas librerías poseen nombres complejos que a priori no son el mismo con el que se llaman directamente, en dichos casos se aconseja buscar directamente la instalación de ellas, en donde por lo general siempre mostraran como instalarla por medio de \"pip\".\n",
        "\n",
        "Para instalar una versión especifica de una librería, uno debe llamar a la función pip de este modo \"pip install NombreLibreria==1.15.0\" en donde siempre podemos desinstalar una libreria ya instalada (dado que queremos otra version) por medio de \"pip uninstall NombreLibreria\" (hay que apretar Y, cuando aparezca el input). Del mismo modo, uno puede hacer esto \"pip install --force-reinstall NombreLibreria==Version\" que en una sola línea desinstala e instala nuevamente la librería deseada.\n",
        "\n",
        "Ejemplo de uso de pip install:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaxWesterhout/Sistemas-de-Diagnostico-y-Tratamiento-I/refs/heads/main/data/Clase10/VisualStudio3.png\" width=\"1000\"/>\n",
        "\n",
        "Cabe destacar que ciertas librerías tienen dependencia con otras librerías, en donde se espera tener versiones compatibles entre ellas, ejemplo de esto es el caso de TensorFlow y Numpy, en donde ciertas versiones antiguas de TensorFlow llaman versiones antiguas de Numpy, por ello no basta solamente con descargar una sino que hay que tener las dos específicas. Además, en ciertos casos esta discrepancia generara errores en el código evitando la ejecución correcta de este."
      ],
      "metadata": {
        "id": "iLurm7LITWCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Congelar un ambiente virtual"
      ],
      "metadata": {
        "id": "OciYGFaqIajE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teniendo el ambiente creado con las librerías deseadas, uno puede \"congelar\" su ambiente por medio de la función \"pip\", en donde uno puede generar un archivo denominado \"requariments.txt\" con todas las librerías asociadas a su ambiente. La creación de dicho archivo se hace por medio de esta línea de código:\n",
        "\n",
        "*   pip freeze > requirements.txt (terminal)\n",
        "\n",
        "Esto crea un archivo de texto con el nombre de las librerías instaladas en el ambiente virtual, el cual puede ser utilizado posteriormente para clonar en otro ambiente.\n"
      ],
      "metadata": {
        "id": "Xt-dvDSshDdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Clonar un ambiente virtual"
      ],
      "metadata": {
        "id": "jrqpsWh8Id0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teniendo el archivo \"requiariments.txt\", uno puede clonar las librerias de un ambiente virtual desde uno nuevo, por medio de pip aplicando la siguiente operacion:\n",
        "\n",
        "*   pip install -r requirements.txt (terminal)\n",
        "\n",
        "En donde se tiene pensado que el archivo requirements es exactamente el mismo que el creado en la seccion de congelar. Esto resulta muy util cuando uno quiere replicar resultados de codigos presentes en repositorios, en donde por lo general las personas suben su requirements.txt para poder ser clonados.\n",
        "\n",
        "Ej: https://github.com/milesial/Pytorch-UNet/blob/master/requirements.txt"
      ],
      "metadata": {
        "id": "O1nPOq6Ak1zZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actividad 1: Entornos virtuales"
      ],
      "metadata": {
        "id": "MXG-Jdewmpp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecute en su computador el código de la clase 3 para dos entornos virtuales distintos. Para ello, siga los siguientes pasos:\n",
        "\n",
        "\n",
        "1.   Cree dos carpetas distintas, y cree para cada una de ellas un entorno virtual.\n",
        "2.   Descargue los datos del problema \"mnist.csv\" y guarde una copia en ambas carpetas.\n",
        "3.   Para uno de los entornos, instale todas las librerías necesarias y ejecute el código.\n",
        "4.   Congele dicho entorno virtual y clonelo en la otra carpeta respectiva, verificando que este nuevo entorno también pueda ejecutar dicho código.\n",
        "\n",
        "Ojo: Se asume que el código sea ejecutado desde un archivo .py\n",
        "\n",
        "Link mnist.csv: https://github.com/MaxWesterhout/Sistemas-de-Diagnostico-y-Tratamiento-I/blob/main/data/mnist.csv\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YMwuiko7nG82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Codigo clase 3\n",
        "\n",
        "# Librerias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.decomposition\n",
        "from sklearn.metrics import (homogeneity_score,completeness_score,v_measure_score)\n",
        "from sklearn.manifold import (Isomap,LocallyLinearEmbedding,MDS,TSNE)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Lectura de datos\n",
        "mnist = pd.read_csv(\"mnist.csv\")\n",
        "y = mnist['label']\n",
        "\n",
        "#Función para graficar \"bonito\"\n",
        "def plot_embedding(X, title, ax=None):\n",
        "    X = MinMaxScaler().fit_transform(X)\n",
        "    for digit in np.unique(mnist.label):\n",
        "        ax.scatter(\n",
        "            *X[y == digit].T,\n",
        "            marker=f\"${digit}$\",\n",
        "            s=60,\n",
        "            color=plt.cm.tab10(digit),\n",
        "            alpha=0.3,\n",
        "            zorder=2,\n",
        "        )\n",
        "    shown_images = np.array([[1.0, 1.0]])  # just something big\n",
        "    ax.set_title(title)\n",
        "\n",
        "\n",
        "#Misma descomposición PCA de la clase pasada\n",
        "pca_mnist_2d = sklearn.decomposition.PCA(2)\n",
        "mnist_2d=pca_mnist_2d.fit_transform(mnist.iloc[:,:-1])\n",
        "\n",
        "#Ajustamos un embedding de 2 dimensiones para visualización.\n",
        "tsne_mnist_2d = TSNE(2, perplexity=30.0, random_state=11, init=\"random\")\n",
        "mnist_2d_tsne=tsne_mnist_2d.fit_transform(mnist.iloc[:,:-1])\n",
        "\n",
        "#Primero deben instancias las figuras y luego entregar la posicisión de esta a la función\n",
        "_, ax = plt.subplots(2 , figsize=(8, 8))\n",
        "\n",
        "#TNSE\n",
        "plot_embedding(mnist_2d_tsne, \"TNSE\", ax[0])\n",
        "\n",
        "#PCA\n",
        "plot_embedding(mnist_2d, \"PCA\", ax[1])\n",
        "\n",
        "#Para que aparezca la imagen\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "29UDFNMVoAE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rendimiento y GPU"
      ],
      "metadata": {
        "id": "0oolO3WYIdov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la Actividad 1 pudieron haber enfrentado una serie de problemas de rendimiento, esto tiene que ser un indicador constante que deben observar al ejecutar código de forma local, dado que ahora deben considerar todos los procesos secundarios presentes en su computador.\n",
        "\n",
        "Una forma de observar el rendimiento es por medio del administrador de tareas, el cual se puede abrir con el comando \"Ctrl + Alt + Supr\", aca existe una pestaña llamada Rendimiento que se ve de la siguiente forma:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaxWesterhout/Sistemas-de-Diagnostico-y-Tratamiento-I/refs/heads/main/data/Clase10/RendimientoCPU.png\" width=\"800\"/>\n",
        "\n",
        "Dicha pestaña, permite saber el gasto de memoria RAM que se está utilizando en el momento, en donde como se observa mi equipo posee 8GB de RAM, de los cuales solo puede utilizar 5.9GB, gastando en ese preciso momento 5,1GB en otros procesos. Para ver los procesos específicos hay que dirigirse a la pestaña con el mismo nombre, en donde aparecen de forma automática los procesos que están gastando más memoria en ese momento:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaxWesterhout/Sistemas-de-Diagnostico-y-Tratamiento-I/refs/heads/main/data/Clase10/RendimientoCPU2.png\" width=\"800\"/>\n",
        "\n",
        "Por lo general, los procesos que gastan más recursos son los que se están ejecutando en ese preciso momento, en donde para la imagen anterior no es sorpresa que Google Chrome y Visual Studio Code sean los que están consumiendo más. Por ello, si es que se requiere realizar una tarea que ocupe mucha memoria, es recomendable cerrar todos los procesos secundarios. Esto se puede hacer de manera directa (cerrando las aplicaciones), o desde el mismo administrador de tareas colocando \"finalizar tarea\".\n",
        "\n",
        "Cabe destacar que existen muchas operaciones de Python que consumen una gran cantidad de memoria de manera innecesaria, en donde si uno está trabajando con una memoria limitada, debe ser capaz de poder administrar sus recursos de forma eficiente. A continuación hay algunos ejemplos:\n"
      ],
      "metadata": {
        "id": "rBah_Zp_InHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 1: Print de una matriz enorme (muy ineficiente)"
      ],
      "metadata": {
        "id": "NAa5BWu0HkFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Crear una matriz de 10000 x 10000 de números aleatorios\n",
        "matriz = np.random.rand(10000, 10000)\n",
        "\n",
        "# Imprimir la matriz completa (consumo de memoria + consola colapsada)\n",
        "print(matriz)"
      ],
      "metadata": {
        "id": "rE9vT-DdHyea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 2: Lista gigante en memoria (innecesariamente almacenada)"
      ],
      "metadata": {
        "id": "t9z4-TbYH5CJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una lista con 1 millón de strings grandes\n",
        "lista = [\"x\" * 1000 for _ in range(1000000)]\n",
        "\n",
        "print(\"Lista creada\")"
      ],
      "metadata": {
        "id": "pRJskK_kH0ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 3: Acumulación innecesaria en un bucle"
      ],
      "metadata": {
        "id": "5Pm_823YH_17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Se guardan todos los resultados aunque no se usen\n",
        "datos = []\n",
        "for _ in range(10000000):\n",
        "    datos.append(random.random() * 1000)"
      ],
      "metadata": {
        "id": "HXXAIdtEH6a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GPU"
      ],
      "metadata": {
        "id": "VEennKayGoC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el caso de la GPU es similar, solo que por lo general esta presenta menos memoria. Ahora, no todos los PC poseen una GPU, en donde importa mucho el modelo y cantidad de memoria que estas poseen dado que afectaran directo en el entrenamiento de modelos de Deep Learning. La forma de verificar que modelo se tiene puede ser por medio del mismo administrador de tareas, en donde existirá una pestaña adicional en el rendimiento con el nombre de GPU:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaxWesterhout/Sistemas-de-Diagnostico-y-Tratamiento-I/refs/heads/main/data/Clase10/GPU1.png\" width=\"800\"/>\n",
        "\n",
        "Acá mi PC, muestra que poseo dos GPU ambas de distinta marca, en donde la GPU 0 presenta 4GB de ram y es de la marca NVIDIA GeForce GTX 1650. Esta tarjeta gráfica corresponde a la que utiliza mi equipo internamente para la mayoría de los procesos, en donde es en la práctica la que yo utilizo para entrenar modelos de Deep Learning, la cual claramente es inferior a la que ofrece Google Colab (T4 de 20GB).\n"
      ],
      "metadata": {
        "id": "r1bHnpQLGrw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Librerias de Deep Learning y CUDA"
      ],
      "metadata": {
        "id": "5VPhv306gWWQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para poder utilizar las tarjetas gráficas de NVIDIA con las librerías de Deep Learning, es necesario ajustar el CUDA toolkit que presenta nuestro equipo, en donde estas librerías funcionan en medida de la versión de CUDA que presentamos. Por ello, es relevante saber dos cosas:\n",
        "\n",
        "1.   La versión de CUDA compatible con nuestra tarjeta gráfica / GPU.\n",
        "2.   La versión de la librería que utilizaremos para verificar si es compatible con nuestra versión de CUDA.\n",
        "\n",
        "Por ende, los siguientes links son relevantes:\n",
        "\n",
        "CUDA por GPU: https://developer.nvidia.com/cuda-gpus\n",
        "\n",
        "TensorFlow por CUDA: https://www.tensorflow.org/install/source?hl=es-419#gpu\n",
        "\n",
        "Pytorch por CUDA: https://pytorch.org/get-started/locally/\n",
        "\n",
        "En medida de la versión de CUDA que tengamos, podremos escoger que versione de TensorFlow o pytorch podremos utilizar. Además, tal como se ve en esas tablas existe un margen de holgura, en donde tarjetas gráficas pueden actualizar su versión de CUDA al igual que utilizar versiones previas. Esta modificación como tal puede ser compleja y tediosa pero existe la posibilidad.\n",
        "\n",
        "Ahora en muchos dispositivos esto puede venir instaurado internamente, por lo cual no es necesario una instalación de CUDA especifica, para verificar esto se utiliza la \"cmd\", en donde el comando \"nvidia-smi\" muestra la información referente a la tarjeta gráfica de NVIDIA.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaxWesterhout/Sistemas-de-Diagnostico-y-Tratamiento-I/refs/heads/main/data/Clase10/GPU2.png\" width=\"800\"/>\n",
        "\n",
        "En dicha imagen aparece en la esquina superior derecha la versión de CUDA de mi GPU, y abajo los procesos que se están ejecutando, que en este caso son ninguno.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tBecpiN_doco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actividad 2: Ejecución de código con GPU"
      ],
      "metadata": {
        "id": "MVnisRSOqx9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Codigo TORCH 1\n",
        "import torch\n",
        "\n",
        "def verificar_gpus():\n",
        "    if torch.cuda.is_available():\n",
        "        num_gpus = torch.cuda.device_count()\n",
        "        print(f\"Se detectaron {num_gpus} GPU(s):\")\n",
        "        for i in range(num_gpus):\n",
        "            nombre_gpu = torch.cuda.get_device_name(i)\n",
        "            memoria_total = torch.cuda.get_device_properties(i).total_memory / (1024 ** 3)  # en GB\n",
        "            print(f\"  GPU {i}: {nombre_gpu}, Memoria total: {memoria_total:.2f} GB\")\n",
        "    else:\n",
        "        print(\"No se detectaron GPUs disponibles.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    verificar_gpus()"
      ],
      "metadata": {
        "id": "j4YepgVp3qnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codigo TORCH 2\n",
        "import torch\n",
        "\n",
        "def crear_tensor_grande_en_gpu():\n",
        "    tamano_en_gb = 1\n",
        "    bytes_por_elemento = 4  # float32\n",
        "    num_elementos = (tamano_en_gb * 1024**3) // bytes_por_elemento\n",
        "\n",
        "    # Crear el tensor\n",
        "    tensor = torch.rand(num_elementos, dtype=torch.float32)\n",
        "    print(f\"Tensor creado con {num_elementos:,} elementos (~1 GB).\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        tensor_gpu = tensor.to(\"cuda\")\n",
        "        print(\"Tensor movido a GPU.\")\n",
        "        print(f\"Dispositivo del tensor: {tensor_gpu.device}\")\n",
        "    else:\n",
        "        print(\"No hay GPU disponible. El tensor permanece en CPU.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    crear_tensor_grande_en_gpu()\n",
        "    input()"
      ],
      "metadata": {
        "id": "7QE4jic-4Wai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra"
      ],
      "metadata": {
        "id": "xXwWCW5r9aAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link dataset: https://github.com/MaxWesterhout/Sistemas-de-Diagnostico-y-Tratamiento-I/blob/main/data/activity_recognition.csv"
      ],
      "metadata": {
        "id": "cEPZpX2C9lwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Comprobar si hay GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Dispositivo:\", device)\n",
        "\n",
        "# 1. Cargar los datos\n",
        "data = pd.read_csv(\"activity_recognition.csv\")\n",
        "features = data.iloc[:, :-1]\n",
        "labels = data['activity']\n",
        "\n",
        "# 2. Normalizar los datos\n",
        "scaler = MinMaxScaler()\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "# 3. Codificar etiquetas (One-Hot Encoding)\n",
        "encoder = LabelEncoder()\n",
        "labels_encoded = encoder.fit_transform(labels)\n",
        "num_classes = len(np.unique(labels_encoded))\n",
        "\n",
        "# Convertir a one-hot encoding manualmente\n",
        "labels_onehot = np.eye(num_classes)[labels_encoded]\n",
        "\n",
        "# 4. Separar conjuntos de entrenamiento, validación y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels_onehot, random_state=11)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=11)\n",
        "\n",
        "# 5. Convertir a tensores de PyTorch\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# 6. Crear DataLoaders\n",
        "batch_size = 5\n",
        "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=batch_size)\n",
        "\n",
        "# 7. Definir modelo\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(MLP, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes),\n",
        "            nn.Softmax(dim=1)  # para multiclase\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = MLP(X_train.shape[1], num_classes).to(device)\n",
        "\n",
        "# 8. Compilar modelo\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 9. Entrenamiento\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, torch.argmax(y_batch, dim=1))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Época {epoch+1}/{epochs} - Pérdida: {total_loss:.4f}\")\n",
        "\n",
        "    # Validación\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_preds = model(X_val_tensor.to(device))\n",
        "        val_preds_labels = torch.argmax(val_preds, dim=1).cpu().numpy()\n",
        "        val_true_labels = torch.argmax(y_val_tensor, dim=1).numpy()\n",
        "        acc = accuracy_score(val_true_labels, val_preds_labels)\n",
        "        print(f\"  -> Exactitud en validación: {acc:.4f}\")"
      ],
      "metadata": {
        "id": "sLZirimp9bCg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}